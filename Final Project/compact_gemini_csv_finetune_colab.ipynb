{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compact Colab: Gemini + CSV + Fine-tuning (Vertex AI)\n",
        "Minimal, end-to-end. Fill the TODOs, then run top to bottom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\n# 0) Setup\n!pip -q install --upgrade google-cloud-aiplatform vertexai google-auth google-auth-oauthlib pandas pyarrow\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\n# 1) Auth and project init\nfrom google.colab import auth\nauth.authenticate_user()\n\nimport os\nPROJECT_ID = \"YOUR_PROJECT_ID\"          # TODO: set me\nLOCATION   = \"us-central1\"              # TODO: set region if needed\nos.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n\nimport vertexai\nvertexai.init(project=PROJECT_ID, location=LOCATION)\nprint(\"OK: Authenticated and vertexai initialized\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\n# 2) Load CSV\n# If your CSV is in Drive, first: from google.colab import drive; drive.mount(\"/content/drive\")\nimport pandas as pd\n\nCSV_PATH = \"/content/sample.csv\"  # TODO: set your CSV path\ndf = pd.read_csv(CSV_PATH)\nprint(\"Rows:\", len(df), \"Cols:\", len(df.columns))\ndf.head(3)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\n# 3) Quick look with Gemini using a small preview (no fine-tune yet)\n# We send a small slice to keep prompts short\nfrom vertexai.generative_models import GenerativeModel, Part\n\npreview_rows = df.head(5).to_csv(index=False)\nprompt = (\n    \"You are a data assistant. Here is a CSV preview. \"\n    \"Describe columns, types, potential target, and basic ideas for modeling in 5 bullets.\\n\\n\"\n    f\"{preview_rows}\"\n)\n\nmodel_name = \"gemini-1.5-flash-002\"  # Use a supported generation model in your region\nbase_model = GenerativeModel(model_name)\nresp = base_model.generate_content(prompt)\nprint(resp.text)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\n# 4) Build a tiny SFT JSONL from CSV rows\n# Format: {\"input_text\": \"...\", \"output_text\": \"...\"}\n# Here we assume a supervised text task. Adjust template as needed for your use case.\nimport json\n\n# TODO: set your target column if you have one, else we do a generic Q&A\nTARGET_COL = None  # e.g., \"label\"\n\ndef row_to_pair(row):\n    if TARGET_COL and TARGET_COL in row and str(row[TARGET_COL]) != \"nan\":\n        y = str(row[TARGET_COL])\n        x = row.drop(TARGET_COL).to_dict()\n        # Simple instruction style\n        prompt = f\"Given features {x}, predict the target.\"\n        return {\"input_text\": prompt, \"output_text\": y}\n    else:\n        # Generic pattern: ask the model to summarize the row in one sentence\n        x = row.to_dict()\n        prompt = f\"Summarize this record in one sentence: {x}\"\n        return {\"input_text\": prompt, \"output_text\": \"A concise one sentence summary.\"}\n\n# Keep this small for demo. For real tuning, build a larger set.\nn = min(200, len(df))  # cap to 200 examples to stay compact\nrecords = [row_to_pair(df.iloc[i]) for i in range(n)]\njsonl_path = \"/content/train.jsonl\"\nwith open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n    for r in records:\n        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n\nprint(\"Wrote\", jsonl_path, \"with\", len(records), \"examples\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\n# 5) Upload JSONL to GCS\n# Requires that you have a bucket created and you have write access.\nBUCKET = \"gs://YOUR_BUCKET_NAME\"   # TODO: set your bucket\nGCS_URI = f\"{BUCKET}/gemini_sft/train.jsonl\"\n\n# Use the Python storage client or gcloud storage copy. We use gcloud for brevity.\n!gcloud storage cp /content/train.jsonl \"$GCS_URI\"\nprint(\"Uploaded to:\", GCS_URI)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\n# 6) Start a Gemini SFT tuning job\n# Note: Supported base models and regions can change. If it errors, switch to a supported base model.\nfrom vertexai.tuning import sft\n\nBASE_MODEL = \"publishers/google/models/gemini-1.5-flash-002\"  # TODO: change if needed\nTUNED_MODEL_DISPLAY_NAME = \"gemini-sft-demo\"                   # TODO: rename if needed\n\ntuned_model = sft.train(\n    model=BASE_MODEL,\n    training_data_uri=GCS_URI,\n    tuned_model_display_name=TUNED_MODEL_DISPLAY_NAME,\n    epoch_count=3,\n    batch_size=4,\n    learning_rate=2e-5\n)\n\nprint(\"Tuning started. Tuned model name: \", tuned_model.resource_name)\nprint(\"State:\", tuned_model.state)  # may be PENDING or RUNNING right after submission\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\n# 7) Use the tuned model when it is ready\n# You can rerun this cell later. Once state is SUCCEEDED, call it like a normal GenerativeModel.\nfrom vertexai.generative_models import GenerativeModel\n\ntuned_name = tuned_model.resource_name  # looks like: projects/../locations/../models/..\ntuned = GenerativeModel(tuned_name)\n\ntest_prompt = \"Test the tuned model on a small example input.\"\nout = tuned.generate_content(test_prompt)\nprint(out.text)\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}